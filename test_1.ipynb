{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL VARIABLES & DATASET LOAD\n",
    "IMAGE_SIZE = 256\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 20\n",
    "\n",
    "df = pd.read_csv(\"markdown_3.csv\",\n",
    "    names=[\"filename\", \"dates\", \"material_1\", \"material_2\",\n",
    "           \"material_3\", \"technique\", \"stamps\", \"casing\"], dtype={'casing': bool})\n",
    "df.head()\n",
    "\n",
    "filename = df['filename'].to_list() # make list of all file paths to images\n",
    "#filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace(np.nan, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>dates</th>\n",
       "      <th>material_1</th>\n",
       "      <th>material_2</th>\n",
       "      <th>material_3</th>\n",
       "      <th>technique</th>\n",
       "      <th>stamps</th>\n",
       "      <th>casing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dataset\\0001.jpg</td>\n",
       "      <td>XV в.</td>\n",
       "      <td>Дерево</td>\n",
       "      <td>Левкас</td>\n",
       "      <td>None</td>\n",
       "      <td>Темпера</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dataset\\0002.jpg</td>\n",
       "      <td>XVI в.</td>\n",
       "      <td>Дерево</td>\n",
       "      <td>Левкас</td>\n",
       "      <td>None</td>\n",
       "      <td>Темпера</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dataset\\0003.jpg</td>\n",
       "      <td>XV в.</td>\n",
       "      <td>Дерево</td>\n",
       "      <td>Левкас</td>\n",
       "      <td>None</td>\n",
       "      <td>Темпера</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dataset\\0004.jpg</td>\n",
       "      <td>XVI в.</td>\n",
       "      <td>Дерево</td>\n",
       "      <td>Левкас</td>\n",
       "      <td>None</td>\n",
       "      <td>Темпера</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dataset\\0005.jpg</td>\n",
       "      <td>XVI–XVII в.</td>\n",
       "      <td>Дерево</td>\n",
       "      <td>Левкас</td>\n",
       "      <td>Паволока</td>\n",
       "      <td>Темпера</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>dataset\\1124.jpg</td>\n",
       "      <td>XVII в.</td>\n",
       "      <td>Дерево</td>\n",
       "      <td>Левкас</td>\n",
       "      <td>Паволока</td>\n",
       "      <td>Темпера</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>dataset\\1125.jpg</td>\n",
       "      <td>XVI в.</td>\n",
       "      <td>Дерево</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Темпера</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>dataset\\1126.jpg</td>\n",
       "      <td>XVII в.</td>\n",
       "      <td>Дерево</td>\n",
       "      <td>Левкас</td>\n",
       "      <td>Паволока</td>\n",
       "      <td>Темпера</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>dataset\\1127.jpg</td>\n",
       "      <td>XVI в.</td>\n",
       "      <td>Дерево</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Темпера</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>dataset\\1128.jpg</td>\n",
       "      <td>XVI в.</td>\n",
       "      <td>Дерево</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Темпера</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1128 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              filename        dates material_1 material_2 material_3   \n",
       "0     dataset\\0001.jpg        XV в.     Дерево     Левкас       None  \\\n",
       "1     dataset\\0002.jpg       XVI в.     Дерево     Левкас       None   \n",
       "2     dataset\\0003.jpg        XV в.     Дерево     Левкас       None   \n",
       "3     dataset\\0004.jpg       XVI в.     Дерево     Левкас       None   \n",
       "4     dataset\\0005.jpg  XVI–XVII в.     Дерево     Левкас   Паволока   \n",
       "...                ...          ...        ...        ...        ...   \n",
       "1123  dataset\\1124.jpg      XVII в.     Дерево     Левкас   Паволока   \n",
       "1124  dataset\\1125.jpg       XVI в.     Дерево       None       None   \n",
       "1125  dataset\\1126.jpg      XVII в.     Дерево     Левкас   Паволока   \n",
       "1126  dataset\\1127.jpg       XVI в.     Дерево       None       None   \n",
       "1127  dataset\\1128.jpg       XVI в.     Дерево       None       None   \n",
       "\n",
       "     technique  stamps  casing  \n",
       "0      Темпера   False   False  \n",
       "1      Темпера   False   False  \n",
       "2      Темпера   False   False  \n",
       "3      Темпера   False   False  \n",
       "4      Темпера   False   False  \n",
       "...        ...     ...     ...  \n",
       "1123   Темпера   False   False  \n",
       "1124   Темпера   False   False  \n",
       "1125   Темпера   False   False  \n",
       "1126   Темпера   False   False  \n",
       "1127   Темпера   False   False  \n",
       "\n",
       "[1128 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGING IMAGE SIZE TO SQUARE\n",
    "import os\n",
    "def padding(path):\n",
    "    # read image\n",
    "    img = cv2.imread(os.path.join(os.path.curdir, path))\n",
    "    old_h, old_w, channels = img.shape\n",
    "\n",
    "    # create new image of desired size and color (white) for padding\n",
    "    new_w = max(old_h, old_w)\n",
    "    new_h = max(old_h, old_w)\n",
    "    color = (255,255,255)\n",
    "    result = np.full((new_h,new_w, channels), color, dtype=np.uint8)\n",
    "\n",
    "    # compute center offset\n",
    "    x_center = (new_w - old_w) // 2\n",
    "    y_center = (new_h - old_h) // 2\n",
    "\n",
    "    # copy img image into center of result image\n",
    "    result[y_center:y_center+old_h, \n",
    "        x_center:x_center+old_w] = img\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPROCESSING TRAINING DATA\n",
    "pic_matrix = [] # will contain numerical representation of images\n",
    "\n",
    "for i in filename:\n",
    "    image = padding(i)\n",
    "    image = cv2.resize(np.array(image), (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    image = image/255\n",
    "    pic_matrix.append(image)\n",
    "\n",
    "# pic_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['XIII в.', 'ХIХ в.', 'XIV в.', 'XVIII–ХIХ в.', 'XVI в.', 'XII в.', 'XVII–XVIII в.', 'XV в.', 'XIX–XX в.', 'XVIII в.', 'XX в.', 'XVII в.', 'XVI–XVII в.']\n",
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}\n"
     ]
    }
   ],
   "source": [
    "dates = df['dates'].to_list() # make list of all dates\n",
    "\n",
    "#dates\n",
    "label = [] # will contain numerical representaion of dates\n",
    "l = list(set(dates)) # словарь\n",
    "\n",
    "for i in dates:\n",
    "    label.append(l.index(i)) # each date will equal its index in dict\n",
    "\n",
    "print(l)\n",
    "print(set(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Холст', 'Дерево', 'Медный сплав', 'Известковая штукатурка', 'Бронза']\n",
      "{0, 1, 2, 3, 4}\n"
     ]
    }
   ],
   "source": [
    "material_1 = df['material_1'].to_list() # make list of all dates\n",
    "\n",
    "#dates\n",
    "label = [] # will contain numerical representaion of dates\n",
    "l = list(set(material_1)) # словарь\n",
    "\n",
    "for i in material_1:\n",
    "    label.append(l.index(i)) # each date will equal its index in dict\n",
    "\n",
    "print(l)\n",
    "print(set(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, 'Жесть', 'Бумага', 'Левкас', 'Посеребренье', 'Эмаль']\n",
      "{0, 1, 2, 3, 4, 5}\n"
     ]
    }
   ],
   "source": [
    "material_2 = df['material_2'].to_list() # make list of all dates\n",
    "\n",
    "#dates\n",
    "label = [] # will contain numerical representaion of dates\n",
    "l = list(set(material_2)) # словарь\n",
    "\n",
    "for i in material_2:\n",
    "    label.append(l.index(i)) # each date will equal its index in dict\n",
    "\n",
    "print(l)\n",
    "print(set(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, 'Позолота', 'Бархат', 'Паволока']\n",
      "{0, 1, 2, 3}\n"
     ]
    }
   ],
   "source": [
    "material_3 = df['material_3'].to_list() # make list of all dates\n",
    "\n",
    "#dates\n",
    "label = [] # will contain numerical representaion of dates\n",
    "l = list(set(material_3)) # словарь\n",
    "\n",
    "for i in material_3:\n",
    "    label.append(l.index(i)) # each date will equal its index in dict\n",
    "\n",
    "print(l)\n",
    "print(set(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, 'Масло', 'Темпера', 'Смешанная', 'Чеканка', 'Хромолитография', 'Резьба', 'Литье']\n",
      "{0, 1, 2, 3, 4, 5, 6, 7}\n"
     ]
    }
   ],
   "source": [
    "technique = df['technique'].to_list() # make list of all dates\n",
    "\n",
    "#dates\n",
    "label = [] # will contain numerical representaion of dates\n",
    "l = list(set(technique)) # словарь\n",
    "\n",
    "for i in technique:\n",
    "    label.append(l.index(i)) # each date will equal its index in dict\n",
    "\n",
    "print(l)\n",
    "print(set(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, True]\n",
      "{0, 1}\n"
     ]
    }
   ],
   "source": [
    "stamps = df['stamps'].to_list() # make list of all dates\n",
    "\n",
    "#dates\n",
    "label = [] # will contain numerical representaion of dates\n",
    "l = list(set(stamps)) # словарь\n",
    "\n",
    "for i in stamps:\n",
    "    label.append(l.index(i)) # each date will equal its index in dict\n",
    "\n",
    "print(l)\n",
    "print(set(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, True]\n",
      "{0, 1}\n"
     ]
    }
   ],
   "source": [
    "casing = df['casing'].to_list() # make list of all dates\n",
    "\n",
    "#dates\n",
    "label = [] # will contain numerical representaion of dates\n",
    "l = list(set(casing)) # словарь\n",
    "\n",
    "for i in casing:\n",
    "    label.append(l.index(i)) # each date will equal its index in dict\n",
    "\n",
    "print(l)\n",
    "print(set(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(pic_matrix, label, test_size=0.2)\n",
    "# del(pic_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_train = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "# ds_train = ds_train.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "# ds_test = tf.data.Dataset.from_tensor_slices((X_test, Y_test))\n",
    "# ds_test = ds_train.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "ds_train = tf.data.Dataset.from_tensor_slices((pic_matrix, label))\n",
    "ds_train = ds_train.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_num = len(l) # number of classes (in this case, number of different dates)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), padding=\"same\", activation=\"relu\", input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\" ),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\" ),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(class_num, activation='softmax'), #num of classes from len(l)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "history = model.fit(ds_train, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALISATION OF RESULTS\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(EPOCHS)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "a = int(7/2)\n",
    "\n",
    "print(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
